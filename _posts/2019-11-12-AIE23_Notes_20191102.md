---
layout: post
title:  "AI Study Notes - Nov 02<sup>nd</sup> 2019"
date:   2019-11-12 23:00:18 +0800
categories: AI
tags: AI Machinelearning Python
author: Hank.S
---

**关键词**  
*特征工程*  
*模型加载和存储*   
*特征选择*   
*降维*   
*可视化*   



---
* content
{:toc}





# 1. Python机器学习 
## 主流python库和框架
- 通用机器学习   
  - Scikit-learn, 开源，涵盖分类，回归和聚类算法   
  - Spark MLlib
- 数据处理
  - Pandas，数据结构DataFrame   
- 科学计算
  - Numpy，矩阵数据类型，矢量处理  
- 可视化 
  - Matplotlib   
- 特定系列算法  
  - XGBoost
- 深度学习
  - TensorFlow, Keras

## 整体流程   
<center><img width="650px" alt="AI知识结构" src="https://ftp.bmp.ovh/imgs/2019/11/66f9ca0c252ff893.png" /></center>

# 2.特征工程
***“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”***   
*特征工程目的是最大限度地从原始数据中提取特征以供算法和模型使用*


## 特征和模型概述   
- 特征和模型的关系
  - 简单特征 <=> 复杂模型
  - 复杂特征 <=> 简单模型
- 特征工程解决的问题
  - 加工数据为模型可处理的格式，即向量化和规范化
  - 某些方法能加速一些优化算法的收敛性
  - 让数据变得使模型更容易拟合
- 特征工程思考流程
  - 探索：
    - 特征状况：类型，空值，分布（特征选择），异常点，量纲
    - 标签状况：类型，分布
  - 清洗 / 向量化
    - 类别特征编码转为向量: **Onehot**
    - 空值处理
  - 标准化
    - 异常点
    - 量纲是否需要统一
    - 是否需要归一化
    - 分桶离散
	- 离群点处理
  - 特征选择 (过拟合后看看)
    - Filter
    - Wrapper
    - Embed
  - 特征扩展 （欠拟合后看看）
    - 业务总结
    - 组合已有特征 （组合，聚合）  

## 数据预处理 （[参考](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling)）
### 独热码(one-hot-enconding)
- 将一个特征按其值的不同进行二进制编码，比如性别特征列sex可以转成2列sex_male和sex_femle,每列只有0，1两种数值
- Python实现：`pandas.get_dummies()`   

### 空值填充
- 填固定值
- 离散型填众数，连续型填均值
- ML 预测
- 如果空值数量很多，可以丢弃   

### 无量纲化
- 标准化（Z-score standardization）
Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.  
![](http://latex.codecogs.com/gif.latex?x' =\frac{x-\overline{X}}{S}) 

```
from sklearn import preprocessing
import numpy as np

# The function scale provides a quick and easy way to perform this operation on a single array-like dataset:
X_train = np.array([[1., -1., 2.],
                    [2., 0., 0.],
                    [0., 1., -1.]])
X_scaled = preprocessing.scale(X_train)
print('\n--------------scaled----------------------')
print(X_scaled)
print('\n--------------feature mean----------------------')
print(X_scaled.mean(axis=0))
print('\n--------------feature std----------------------')
print(X_scaled.std(axis=0))

"The preprocessing module further provides a utility class StandardScaler that implements the Transformer API to compute the mean and standard deviation on a training set so as to be able to later reapply the same transformation on the testing set. "
scaler = StandardScaler()
print(scaler.fit(X_train))
print(scaler.transform(X_train)) 
```

- 区间缩放 (Scaling features to a range)


- 归一化   

### 对定量特征二值化（对列向量处理）

&nbsp;

---
# 2. 机器学习模型描述方式 
## 概率论
  - 可参考[博文](https://www.cnblogs.com/sench/p/9478284.html)
- 随机事件
  - 样本点，样本空间
  - 随机事件的样本空间是离散的->分类问题
  - 连续的->回归问题 
- 随机变量及其分布   
- 均值    
  - ![均值1](http://latex.codecogs.com/gif.latex?\mathbb {E}(X)=\sum_{i} x_i \cdot p_i)   
  - ![均值2](http://latex.codecogs.com/gif.latex?E(X)=\int_a^b x \cdot p(x)dx)

